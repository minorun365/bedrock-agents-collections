import os
import json
import uuid
import boto3
import streamlit as st
from dotenv import load_dotenv
from botocore.exceptions import ClientError
from botocore.eventstream import EventStreamError

def initialize_session():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®åˆæœŸè¨­å®šã‚’è¡Œã†"""
    if "client" not in st.session_state:
        st.session_state.client = boto3.client("bedrock-agent-runtime")
    
    if "session_id" not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "last_prompt" not in st.session_state:
        st.session_state.last_prompt = None
    
    if "agent_id" not in st.session_state:
        st.session_state.agent_id = ""
    
    if "agent_alias_id" not in st.session_state:
        st.session_state.agent_alias_id = ""
    
    return st.session_state.client, st.session_state.session_id, st.session_state.messages

def display_chat_history(messages):
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹"""
    st.title("ã‚¿ã‚¤ãƒˆãƒ«")
    st.text("èª¬æ˜æ–‡")
    
    for message in messages:
        with st.chat_message(message['role']):
            st.markdown(message['text'])

def handle_trace_event(event):
    """ãƒˆãƒ¬ãƒ¼ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†ã‚’è¡Œã†"""
    if "orchestrationTrace" not in event["trace"]["trace"]:
        return
    
    trace = event["trace"]["trace"]["orchestrationTrace"]
    
    # ã€Œãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "modelInvocationInput" in trace:
        with st.expander("ğŸ¤” æ€è€ƒä¸­â€¦", expanded=False):
            input_trace = trace["modelInvocationInput"]["text"]
            try:
                st.json(json.loads(input_trace))
            except:
                st.write(input_trace)
    
    # ã€Œãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "modelInvocationOutput" in trace:
        output_trace = trace["modelInvocationOutput"]["rawResponse"]["content"]
        with st.expander("ğŸ’¡ æ€è€ƒãŒã¾ã¨ã¾ã‚Šã¾ã—ãŸ", expanded=False):
            try:
                thinking = json.loads(output_trace)["content"][0]["text"]
                if thinking:
                    st.write(thinking)
                else:
                    st.write(json.loads(output_trace)["content"][0])
            except:
                st.write(output_trace)
    
    # ã€Œæ ¹æ‹ ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "rationale" in trace:
        with st.expander("âœ… æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®šã—ã¾ã—ãŸ", expanded=True):
            st.write(trace["rationale"]["text"])
    
    # ã€Œãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "invocationInput" in trace:
        invocation_type = trace["invocationInput"]["invocationType"]
        
        if invocation_type == "AGENT_COLLABORATOR":
            agent_name = trace["invocationInput"]["agentCollaboratorInvocationInput"]["agentCollaboratorName"]
            with st.expander(f"ğŸ¤– ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Œ{agent_name}ã€ã‚’å‘¼ã³å‡ºã—ä¸­â€¦", expanded=True):
                st.write(trace["invocationInput"]["agentCollaboratorInvocationInput"]["input"]["text"])
        
        elif invocation_type == "KNOWLEDGE_BASE":
            with st.expander("ğŸ“– ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­â€¦", expanded=False):
                st.write(trace["invocationInput"]["knowledgeBaseLookupInput"]["text"])
        
        elif invocation_type == "ACTION_GROUP":
            with st.expander("ğŸ’» Lambdaã‚’å®Ÿè¡Œä¸­â€¦", expanded=False):
                st.write(trace['invocationInput']['actionGroupInvocationInput'])
    
    # ã€Œè¦³å¯Ÿã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
    if "observation" in trace:
        obs_type = trace["observation"]["type"]
        
        if obs_type == "KNOWLEDGE_BASE":
            with st.expander("ğŸ” ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ¤œç´¢çµæœã‚’å–å¾—ã—ã¾ã—ãŸ", expanded=False):
                st.write(trace["observation"]["knowledgeBaseLookupOutput"]["retrievedReferences"])
        
        elif obs_type == "AGENT_COLLABORATOR":
            agent_name = trace["observation"]["agentCollaboratorInvocationOutput"]["agentCollaboratorName"]
            with st.expander(f"ğŸ¤– ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Œ{agent_name}ã€ã‹ã‚‰å›ç­”ã‚’å–å¾—ã—ã¾ã—ãŸ", expanded=True):
                st.write(trace["observation"]["agentCollaboratorInvocationOutput"]["output"]["text"])

def invoke_bedrock_agent(client, session_id, prompt, agent_id, agent_alias_id):
    """Bedrockã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™"""
    return client.invoke_agent(
        agentId=agent_id,
        agentAliasId=agent_alias_id,
        sessionId=session_id,
        enableTrace=True,
        inputText=prompt,
    )

def handle_agent_response(response, messages):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹"""
    with st.chat_message("assistant"):
        for event in response.get("completion"):
            if "trace" in event:
                handle_trace_event(event)
            
            if "chunk" in event:
                answer = event["chunk"]["bytes"].decode()
                st.write(answer)
                messages.append({"role": "assistant", "text": answer})

def show_error_popup(exeption):
    """ã‚¨ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã‚’è¡¨ç¤ºã™ã‚‹"""
    if exeption == "dependencyFailedException":
        error_message = "ã€ã‚¨ãƒ©ãƒ¼ã€‘ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®Aurora DBãŒã‚¹ãƒªãƒ¼ãƒ—ã—ã¦ã„ãŸã‚ˆã†ã§ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ğŸ™"
    elif exeption == "throttlingException":
        error_message = "ã€ã‚¨ãƒ©ãƒ¼ã€‘Bedrockã®ãƒ¢ãƒ‡ãƒ«è² è·ãŒé«˜ã„ã‚ˆã†ã§ã™ã€‚1åˆ†å¾Œã«ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ğŸ™ï¼ˆæ”¹å–„ã—ãªã„å ´åˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ã™ã‚‹ã‹[ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ã‚©ãƒ¼ã‚¿ã®å¼•ãä¸Šã’ç”³è«‹](https://aws.amazon.com/jp/blogs/news/generative-ai-amazon-bedrock-handling-quota-problems/)ã‚’å®Ÿæ–½ãã ã•ã„ï¼‰"
    st.error(error_message)

def main():
    """ãƒ¡ã‚¤ãƒ³ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†"""
    client, session_id, messages = initialize_session()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’é…ç½®
    with st.sidebar:
        st.session_state.agent_id = st.text_input("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ID", value=st.session_state.agent_id)
        st.session_state.agent_alias_id = st.text_input("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ID", value=st.session_state.agent_alias_id)
    
    display_chat_history(messages)
    
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDã¨ã‚¨ã‚¤ãƒªã‚¢ã‚¹IDãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚’è¡¨ç¤º
    if st.session_state.agent_id and st.session_state.agent_alias_id:
        if prompt := st.chat_input("è³ªå•ã—ã¦ã­"):
            messages.append({"role": "human", "text": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            try:
                response = invoke_bedrock_agent(client, session_id, prompt, st.session_state.agent_id, st.session_state.agent_alias_id)
                handle_agent_response(response, messages)
                
            except (EventStreamError, ClientError) as e:
                if "dependencyFailedException" in str(e):
                    show_error_popup("dependencyFailedException")
                elif "throttlingException" in str(e):
                    show_error_popup("throttlingException")
                else:
                    raise e
    else:
        st.info("æœ€åˆã«ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDã¨ã‚¨ã‚¤ãƒªã‚¢ã‚¹IDã‚’è¨­å®šã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    main()